{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. INTRO TO AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takosaga/miniconda3/envs/agent/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env file \n",
    "load_dotenv('my.env')\n",
    "\n",
    "# get token from .env file\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\"https://jc26mwg228mkj8dw.us-east-1.aws.endpoints.huggingface.cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris. The capital of Italy is Rome. The capital of Spain is Madrid. The capital of Germany is Berlin. The capital of the United Kingdom is London. The capital of Australia is Canberra. The capital of China is Beijing. The capital of Japan is Tokyo. The capital of India is New Delhi. The capital of Brazil is Brasília. The capital of Russia is Moscow. The capital of South Africa is Pretoria. The capital of Egypt is Cairo. The capital of Turkey is Ankara. The\n"
     ]
    }
   ],
   "source": [
    "output = client.text_generation(\n",
    "    \"The capital of France is\",\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "...Paris!\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "The capital of France is<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "output = client.text_generation(\n",
    "    prompt,\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "client = InferenceClient(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "output = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"The capital of France is\"},\n",
    "    ],\n",
    "    stream=False,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "print(output.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris."
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "stream = chat(\n",
    "    model='llama3.2',\n",
    "    messages=[{'role': 'user', 'content': 'The capital of France is'}],\n",
    "    stream=True,\n",
    "    \n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">What is the weather in Tokyo?</span>                                                                                   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - ollama_chat/llama3.2 ───────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mWhat is the weather in Tokyo?\u001b[0m                                                                                   \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - ollama_chat/llama3.2 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'get_weather' with arguments: {'celsius': None, 'location': 'Tokyo'}                              │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'get_weather' with arguments: {'celsius': None, 'location': 'Tokyo'}                              │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: The weather in Tokyo is sunny with temperatures around <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>°C.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: The weather in Tokyo is sunny with temperatures around \u001b[1;36m25\u001b[0m°C.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 1.11 seconds| Input tokens: 1,112 | Output tokens: 24]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 1.11 seconds| Input tokens: 1,112 | Output tokens: 24]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'get_weather' with arguments: {'location': 'Tokyo'}                                               │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'get_weather' with arguments: {'location': 'Tokyo'}                                               │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: The weather in Tokyo is sunny with temperatures around <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>°C.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: The weather in Tokyo is sunny with temperatures around \u001b[1;36m25\u001b[0m°C.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 0.55 seconds| Input tokens: 2,340 | Output tokens: 42]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 0.55 seconds| Input tokens: 2,340 | Output tokens: 42]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': 'Tokyo has a pleasant weather, perfect for              │\n",
       "│ sightseeing.'}                                                                                                  │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': 'Tokyo has a pleasant weather, perfect for              │\n",
       "│ sightseeing.'}                                                                                                  │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: Tokyo has a pleasant weather, perfect for sightseeing.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: Tokyo has a pleasant weather, perfect for sightseeing.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 0.75 seconds| Input tokens: 3,683 | Output tokens: 70]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 0.75 seconds| Input tokens: 3,683 | Output tokens: 70]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo has a pleasant weather, perfect for sightseeing.\n"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, LiteLLMModel, PythonInterpreterTool, tool\n",
    "from typing import Optional\n",
    "\n",
    "# model = LiteLLMModel(model_id=\"ollama/qwen2.5-coder:7b\")\n",
    "\n",
    "model = LiteLLMModel(\n",
    "    model_id=\"ollama_chat/llama3.2\", # This model is a bit weak for agentic behaviours though\n",
    "    api_base=\"http://localhost:11434\", # replace with 127.0.0.1:11434 or remote open-ai compatible server if necessary\n",
    "    api_key=\"YOUR_API_KEY\", # replace with API key if necessary\n",
    "    num_ctx=8192, # ollama default is 2048 which will fail horribly. 8192 works for easy tasks, more is better. Check https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator to calculate how much VRAM this will need for the selected model.\n",
    ")\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str, celsius: Optional[bool] = False) -> str:\n",
    "    \"\"\"\n",
    "    Get weather in the next days at given location.\n",
    "    Args:\n",
    "        location: the location\n",
    "        celsius: whether to use Celsius for temperature\n",
    "    \"\"\"\n",
    "    return f\"The weather in {location} is sunny with temperatures around 25°C.\"\n",
    "\n",
    "agent = ToolCallingAgent(tools=[get_weather], model=model)\n",
    "\n",
    "\n",
    "# agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model, additional_authorized_imports=[\"requests\", \"re\"])\n",
    "\n",
    "answer = agent.run(\"What is the weather in Tokyo?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Could you give me the 118th number in the Fibonacci sequence?</span>                                                   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ LiteLLMModel - ollama_chat/llama3.2 ───────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mCould you give me the 118th number in the Fibonacci sequence?\u001b[0m                                                   \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m LiteLLMModel - ollama_chat/llama3.2 \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Initialize the first two numbers in the sequence</span><span style=\"background-color: #272822\">                                                             </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">a </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                                                                          </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">b </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"background-color: #272822\">                                                                                                          </span>  \n",
       "  <span style=\"background-color: #272822\">                                                                                                               </span>  \n",
       "  <span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Find the 118th number in the Fibonacci sequence</span><span style=\"background-color: #272822\">                                                              </span>  \n",
       "  <span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">for</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> _ </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> range(</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">2</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">119</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">):</span><span style=\"background-color: #272822\">                                                                                        </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    a, b </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> b, a </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">+</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> b</span><span style=\"background-color: #272822\">                                                                                            </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(a)</span><span style=\"background-color: #272822\">                                                                                                </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Initialize the first two numbers in the sequence\u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34ma\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mb\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m  \n",
       "  \u001b[48;2;39;40;34m                                                                                                               \u001b[0m  \n",
       "  \u001b[38;2;149;144;119;48;2;39;40;34m# Find the 118th number in the Fibonacci sequence\u001b[0m\u001b[48;2;39;40;34m                                                              \u001b[0m  \n",
       "  \u001b[38;2;102;217;239;48;2;39;40;34mfor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m_\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrange\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m2\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m119\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34ma\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mb\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mb\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34ma\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m+\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mb\u001b[0m\u001b[48;2;39;40;34m                                                                                            \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34ma\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: 1264937032042997393488322</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: 1264937032042997393488322\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 9.26 seconds| Input tokens: 2,117 | Output tokens: 122]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 9.26 seconds| Input tokens: 2,117 | Output tokens: 122]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1264937032042997393488322"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smolagents import CodeAgent, LiteLLMModel\n",
    "\n",
    "model = LiteLLMModel(\n",
    "    model_id=\"ollama_chat/llama3.2\", # This model is a bit weak for agentic behaviours though\n",
    "    api_base=\"http://localhost:11434\", # replace with 127.0.0.1:11434 or remote open-ai compatible server if necessary\n",
    "    api_key=\"YOUR_API_KEY\", # replace with API key if necessary\n",
    "    num_ctx=8192, # ollama default is 2048 which will fail horribly. 8192 works for easy tasks, more is better. Check https://huggingface.co/spaces/NyxKrage/LLM-Model-VRAM-Calculator to calculate how much VRAM this will need for the selected model.\n",
    ")\n",
    "\n",
    "agent = CodeAgent(tools=[], model=model, add_base_tools=True)\n",
    "\n",
    "agent.run(\n",
    "    \"Could you give me the 118th number in the Fibonacci sequence?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trafilatura\n",
    "\n",
    "download = trafilatura.fetch_url('https://github.com/adbar/trafilatura')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trafilatura is a cutting-edge Python package and command-line tool designed to gather text on the Web and simplify the process of turning raw HTML into structured, meaningful data. It includes all necessary discovery and text processing components to perform web crawling, downloads, scraping, and extraction of main texts, metadata and comments. It aims at staying handy and modular: no database is required, the output can be converted to commonly used formats.\n",
      "Going from HTML bulk to essential parts can alleviate many problems related to text quality, by focusing on the actual content, avoiding the noise caused by recurring elements like headers and footers and by making sense of the data and metadata with selected information. The extractor strikes a balance between limiting noise (precision) and including all valid parts (recall). It is robust and reasonably fast.\n",
      "Trafilatura is widely used and integrated into thousands of projects by companies like HuggingFace, IBM, and Microsoft Research as well as institutions like the Allen Institute, Stanford, the Tokyo Institute of Technology, and the University of Munich.\n",
      "-\n",
      "Advanced web crawling and text discovery:\n",
      "- Support for sitemaps (TXT, XML) and feeds (ATOM, JSON, RSS)\n",
      "- Smart crawling and URL management (filtering and deduplication)\n",
      "-\n",
      "Parallel processing of online and offline input:\n",
      "- Live URLs, efficient and polite processing of download queues\n",
      "- Previously downloaded HTML files and parsed HTML trees\n",
      "-\n",
      "Robust and configurable extraction of key elements:\n",
      "- Main text (common patterns and generic algorithms like jusText and readability)\n",
      "- Metadata (title, author, date, site name, categories and tags)\n",
      "- Formatting and structure: paragraphs, titles, lists, quotes, code, line breaks, in-line text formatting\n",
      "- Optional elements: comments, links, images, tables\n",
      "-\n",
      "Multiple output formats:\n",
      "- TXT and Markdown\n",
      "- CSV\n",
      "- JSON\n",
      "- HTML, XML and XML-TEI\n",
      "-\n",
      "Optional add-ons:\n",
      "- Language detection on extracted content\n",
      "- Speed optimizations\n",
      "-\n",
      "Actively maintained with support from the open-source community:\n",
      "- Regular updates, feature additions, and optimizations\n",
      "- Comprehensive documentation\n",
      "Trafilatura consistently outperforms other open-source libraries in text extraction benchmarks, showcasing its efficiency and accuracy in extracting web content. The extractor tries to strike a balance between limiting noise and including all valid parts.\n",
      "For more information see the benchmark section and the evaluation readme to run the evaluation with the latest data and packages.\n",
      "- Most efficient open-source library in ScrapingHub's article extraction benchmark\n",
      "- Best overall tool according to Bien choisir son outil d'extraction de contenu à partir du Web (Lejeune & Barbaresi 2020)\n",
      "- Best single tool by ROUGE-LSum Mean F1 Page Scores in An Empirical Comparison of Web Content Extraction Algorithms (Bevendorff et al. 2023)\n",
      "Getting started with Trafilatura is straightforward. For more information and detailed guides, visit Trafilatura's documentation:\n",
      "- Installation\n",
      "- Usage: On the command-line, With Python, With R\n",
      "- Core Python functions\n",
      "- Interactive Python Notebook: Trafilatura Overview\n",
      "- Tutorials and use cases\n",
      "Youtube playlist with video tutorials in several languages:\n",
      "This package is distributed under the Apache 2.0 license.\n",
      "Versions prior to v1.8.0 are under GPLv3+ license.\n",
      "Contributions of all kinds are welcome. Visit the Contributing page for more information. Bug reports can be filed on the dedicated issue page.\n",
      "Many thanks to the contributors who extended the docs or submitted bug reports, features and bugfixes!\n",
      "This work started as a PhD project at the crossroads of linguistics and NLP, this expertise has been instrumental in shaping Trafilatura over the years. Initially launched to create text databases for research purposes at the Berlin-Brandenburg Academy of Sciences (DWDS and ZDL units), this package continues to be maintained but its future depends on community support.\n",
      "If you value this software or depend on it for your product, consider sponsoring it and contributing to its codebase. Your support on GitHub or ko-fi.com will help maintain and enhance this popular package.\n",
      "Trafilatura is an Italian word for wire drawing symbolizing the refinement and conversion process. It is also the way shapes of pasta are formed.\n",
      "Reach out via ia the software repository or the contact page for inquiries, collaborations, or feedback. See also social networks for the latest updates.\n",
      "- Barbaresi, A. Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction, Proceedings of ACL/IJCNLP 2021: System Demonstrations, 2021, p. 122-131.\n",
      "- Barbaresi, A. \"Generic Web Content Extraction with Open-Source Software\", Proceedings of KONVENS 2019, Kaleidoscope Abstracts, 2019.\n",
      "- Barbaresi, A. \"Efficient construction of metadata-enhanced web corpora\", Proceedings of the 10th Web as Corpus Workshop (WAC-X), 2016.\n",
      "Trafilatura is widely used in the academic domain, chiefly for data acquisition. Here is how to cite it:\n",
      "@inproceedings{barbaresi-2021-trafilatura,\n",
      "title = {{Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction}},\n",
      "author = \"Barbaresi, Adrien\",\n",
      "booktitle = \"Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations\",\n",
      "pages = \"122--131\",\n",
      "publisher = \"Association for Computational Linguistics\",\n",
      "url = \"https://aclanthology.org/2021.acl-demo.15\",\n",
      "year = 2021,\n",
      "}\n",
      "Jointly developed plugins and additional packages also contribute to the field of web data extraction and analysis:\n",
      "Corresponding posts can be found on Bits of Language.\n",
      "Impressive, you have reached the end of the page: Thank you for your interest!\n"
     ]
    }
   ],
   "source": [
    "print(trafilatura.extract(download))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
